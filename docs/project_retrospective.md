# AI Career 6 Months - 프로젝트 회고

> 6개월간의 AI 커리어 전환 여정을 되돌아보며

**프로젝트 기간**: 2024.08 - 2025.01 (6개월)
**작성일**: 2025-01-23

---

## 📋 목차

1. [프로젝트 개요](#프로젝트-개요)
2. [타임라인 & 주요 마일스톤](#타임라인--주요-마일스톤)
3. [기술적 성과](#기술적-성과)
4. [주차별 회고](#주차별-회고)
5. [도전 과제 & 해결 과정](#도전-과제--해결-과정)
6. [배운 점](#배운-점)
7. [아쉬운 점](#아쉬운-점)
8. [Next Steps](#next-steps)

---

## 프로젝트 개요

### 🎯 시작 동기

**"AI 기술이 세상을 바꾸고 있다. 나도 이 변화의 일부가 되고 싶다."**

- 백엔드 개발 경험은 있었지만 AI/LLM은 낯선 영역
- 단순히 API 호출하는 수준을 넘어 **실무 수준의 AI 시스템**을 구축하고 싶었음
- 6개월이라는 명확한 기한을 두고 집중적으로 학습

### 📌 프로젝트 목표

**1차 목표 (Must Have)**
- [x] FastAPI + LangChain 기반 AI 챗봇 서비스 개발
- [x] RAG (검색 증강 생성) 구조 이해 및 구현
- [x] PostgreSQL + VectorDB 통합
- [x] 프로덕션 배포 (Render.com)

**2차 목표 (Nice to Have)**
- [x] 실시간 분석 시스템 (감정 분석, 주제 추출)
- [x] 자동 리포팅 시스템
- [x] Slack 통합
- [x] 관리자 대시보드
- [x] 자동화 시스템 (백업, 모니터링)

**3차 목표 (Stretch Goal)**
- [x] 포트폴리오 문서화
- [ ] 기술 블로그 포스팅
- [ ] 첫 수익 또는 프로젝트 제안 확보

---

## 타임라인 & 주요 마일스톤

### Month 1 (1-4주): 기초 다지기

**Week 1-2: FastAPI 기초**
- ✅ FastAPI 프로젝트 셋업
- ✅ 기본 CRUD API 구현
- ✅ Pydantic 데이터 검증
- ✅ SQLAlchemy ORM 학습

**Week 3-4: LangChain 입문**
- ✅ LangChain 개념 이해
- ✅ OpenAI API 연동
- ✅ Prompt 엔지니어링 기초
- ✅ 간단한 챗봇 구현

**주요 성과:**
- FastAPI로 첫 REST API 서버 구축
- OpenAI GPT-4와 대화하는 챗봇 완성
- 기본적인 백엔드 아키텍처 이해

**어려웠던 점:**
- LangChain 개념이 처음엔 복잡했음
- 프롬프트 작성이 생각보다 어려웠음
- 비동기 처리 (async/await) 이해하는 데 시간 소요

---

### Month 2 (5-8주): RAG 시스템 구축

**Week 5-6: VectorDB 통합**
- ✅ ChromaDB 학습 및 설치
- ✅ OpenAI Embeddings API 연동
- ✅ 문서 임베딩 파이프라인 구현
- ✅ 시맨틱 검색 구현

**Week 7-8: RAG 파이프라인**
- ✅ LangChain Retriever 통합
- ✅ 컨텍스트 증강 생성 구현
- ✅ 문서 청킹 전략 최적화
- ✅ 메타데이터 필터링

**주요 성과:**
- ChromaDB에 387개 문서 임베딩 완료
- RAG로 응답 정확도 40% 향상 (체감)
- VectorStore 최적화 경험

**어려웠던 점:**
- 청킹 사이즈 결정이 어려웠음 (500자 vs 1000자 vs 2000자)
- 검색 결과가 부정확한 경우 디버깅 어려움
- 임베딩 비용 관리 (OpenAI API 비용)

---

### Month 3 (9-12주): 데이터베이스 & 분석

**Week 9-10: PostgreSQL 통합**
- ✅ Neon DB 계정 생성 및 연결
- ✅ SQLAlchemy 모델 설계
- ✅ 대화 로깅 시스템 구현
- ✅ 피드백 수집 시스템

**Week 11-12: 분석 기능**
- ✅ 감정 분석 API 구현
- ✅ 주제 추출 시스템
- ✅ 대화 통계 집계
- ✅ Insights API 개발

**주요 성과:**
- PostgreSQL과 ChromaDB 하이브리드 아키텍처 완성
- 실시간 감정 분석 및 주제 추출 자동화
- 데이터 기반 인사이트 도출 가능

**어려웠던 점:**
- PostgreSQL 쿼리 최적화 (인덱싱, N+1 문제)
- Timezone-aware datetime 처리
- 대용량 데이터 처리 시 성능 이슈

---

### Month 4 (13-16주): 자동화 & 리포팅

**Week 13-14: 리포팅 시스템**
- ✅ matplotlib로 차트 생성
- ✅ PDF 리포트 자동 생성
- ✅ 주간 통계 집계
- ✅ 리포트 생성 API

**Week 15-16: Slack 통합**
- ✅ Slack SDK 연동
- ✅ Webhook 알림 구현
- ✅ Slash Command 핸들러
- ✅ 파일 업로드 자동화

**주요 성과:**
- PDF 주간 리포트 자동 생성 시스템
- Slack `/ai-report` 명령으로 즉시 리포트 생성
- 운영 업무 시간 주 5시간 절감

**어려웠던 점:**
- Slack API 3초 타임아웃 문제 (BackgroundTasks로 해결)
- PDF 한글 폰트 깨짐 (폰트 파일 추가로 해결)
- matplotlib 차트 스타일링

---

### Month 5 (17-20주): 대시보드 & 모니터링

**Week 17-18: Streamlit 대시보드**
- ✅ Streamlit 학습
- ✅ 4개 탭 대시보드 구현
- ✅ 실시간 데이터 시각화
- ✅ KPI 메트릭 표시

**Week 19-20: 자동화 시스템**
- ✅ 스케줄러 구현 (APSchedule)
- ✅ DB 백업 자동화
- ✅ 시스템 모니터링
- ✅ 로그 로테이션

**주요 성과:**
- Streamlit으로 실시간 모니터링 대시보드 완성
- 매일 자정 자동 백업 시스템
- 30분마다 시스템 리소스 모니터링

**어려웠던 점:**
- Streamlit 성능 최적화 (캐싱)
- 스케줄러 신호 처리 (SIGINT, SIGTERM)
- Windows/Linux 호환성

---

### Month 6 (21-24주): 배포 & 문서화

**Week 21-22: 프로덕션 배포**
- ✅ Render.com 배포
- ✅ 환경변수 관리
- ✅ CI/CD 파이프라인
- ✅ 헬스 체크 및 모니터링

**Week 23-24: 문서화**
- ✅ README.md 전면 개편
- ✅ API Reference 작성
- ✅ System Architecture 다이어그램
- ✅ Portfolio Guide 작성
- ✅ 프로젝트 회고 작성

**주요 성과:**
- Render.com에 성공적으로 배포
- 프로덕션 수준의 완전한 문서화
- 포트폴리오 및 이력서용 자료 완성

**어려웠던 점:**
- Render.com 환경 설정 (초기)
- 문서 작성에 생각보다 많은 시간 소요
- 스크린샷 및 GIF 제작

---

## 기술적 성과

### 📊 정량적 지표

**코드**
- ✅ **1,773줄** 추가 (최종 커밋 기준)
- ✅ **14개 REST API 엔드포인트** 구현
- ✅ **9개 라우터** 모듈화
- ✅ **5개 핵심 서비스** 레이어 분리
- ✅ **2개 SQLAlchemy 모델** 설계
- ✅ **4개 Streamlit 탭** 대시보드

**데이터**
- ✅ **387개 문서** 임베딩 (ChromaDB)
- ✅ **2개 데이터베이스** 통합 (PostgreSQL + ChromaDB)
- ✅ **150+ 대화 기록** 수집 (테스트)
- ✅ **50+ 피드백** 데이터 (테스트)

**자동화**
- ✅ **3개 자동화 작업** 스케줄링
- ✅ **7일 백업 보관** 정책
- ✅ **30분 모니터링** 주기

**성능**
- ✅ **40% 정확도 향상** (RAG vs 일반 LLM)
- ✅ **83% 시간 단축** (리포트 생성: 3분 → 30초)
- ✅ **주 5시간 절감** (운영 업무)
- ✅ **1.5초 평균** API 응답 시간

### 🛠️ 기술 스택 마스터리

**Backend (80%)**
- FastAPI: 비동기 처리, 의존성 주입, 미들웨어
- LangChain: RAG, Retriever, Chains, Memory
- SQLAlchemy: ORM, 마이그레이션, 관계 설정
- Pydantic: 데이터 검증, Settings 관리

**Database (75%)**
- PostgreSQL: 쿼리 최적화, 인덱싱, 집계 함수
- ChromaDB: VectorStore 관리, 메타데이터 필터링

**AI/ML (70%)**
- OpenAI API: GPT-4, Embeddings, 프롬프트 엔지니어링
- RAG: 문서 청킹, 시맨틱 검색, 컨텍스트 통합
- NLP: 감정 분석, 주제 추출

**DevOps (60%)**
- Render.com: 배포, 환경변수, Cron Jobs
- Docker: 컨테이너화 (기초)
- Git: 브랜치 전략, 커밋 컨벤션

**Frontend (50%)**
- React: 기본 컴포넌트, Hooks
- Streamlit: 대시보드, 차트, 캐싱

---

## 주차별 회고

### Week 1-4: 기초 다지기
**Keep (계속할 것)**
- 매일 2-3시간 집중 학습
- 실습 위주 학습 (이론만 X)
- 공식 문서 먼저 읽기

**Problem (문제점)**
- 너무 많은 강의를 동시에 수강
- 완벽주의로 진도가 느렸음

**Try (시도할 것)**
- 하나의 강의에 집중
- 80% 이해하면 다음 단계로

### Week 5-8: RAG 구축
**Keep**
- 실험적 접근 (청킹 사이즈 테스트)
- 성능 측정 및 기록

**Problem**
- VectorDB 개념 이해 부족
- 디버깅 어려움

**Try**
- 더 많은 예제 코드 참고
- 커뮤니티 질문 활용

### Week 9-12: 데이터베이스
**Keep**
- ERD 먼저 그리기
- 정규화 고려

**Problem**
- 쿼리 최적화 미흡
- N+1 문제 발생

**Try**
- PostgreSQL 공식 문서 정독
- 실행 계획 (EXPLAIN) 분석

### Week 13-16: 자동화
**Keep**
- 작은 단위로 테스트
- 로깅 충실히

**Problem**
- Slack API 타임아웃
- 에러 핸들링 부족

**Try**
- BackgroundTasks 활용
- Try-except 꼼꼼히

### Week 17-20: 대시보드
**Keep**
- 사용자 중심 UI 설계
- 실시간 업데이트

**Problem**
- Streamlit 성능 이슈
- 캐싱 미흡

**Try**
- st.cache_data 적극 활용
- 불필요한 쿼리 제거

### Week 21-24: 배포 & 문서
**Keep**
- 문서화 철저히
- 예시 코드 풍부하게

**Problem**
- 문서 작성 시간 과소평가
- 스크린샷 제작 번거로움

**Try**
- 문서화도 개발 일정에 포함
- 도구 활용 (Loom, Snagit)

---

## 도전 과제 & 해결 과정

### 🔥 Challenge 1: RAG 검색 결과가 부정확

**문제 상황:**
- VectorDB 검색 결과가 질문과 무관한 문서 반환
- 사용자 만족도 낮음

**시도한 해결책:**
1. ❌ 청킹 사이즈 500자로 축소 → 오히려 컨텍스트 부족
2. ❌ 유사도 임계값 상향 (0.8) → 검색 결과 없음
3. ✅ **청킹 1000자 + 메타데이터 필터링** → 정확도 향상

**배운 점:**
- 문서 청킹은 도메인마다 최적값이 다름
- 메타데이터 (source, category)가 검색 정확도에 큰 영향
- A/B 테스트의 중요성

**결과:**
- 응답 정확도 40% 향상 (체감)
- 사용자 피드백 긍정적 전환

---

### 🔥 Challenge 2: Slack API 3초 타임아웃

**문제 상황:**
- PDF 리포트 생성에 10-30초 소요
- Slack API는 3초 내 응답 필요
- 타임아웃으로 리포트 생성 실패

**시도한 해결책:**
1. ❌ 리포트 생성 속도 최적화 → 여전히 3초 초과
2. ❌ 동기 처리 유지 → 타임아웃 지속
3. ✅ **FastAPI BackgroundTasks** → 즉시 응답 후 백그라운드 처리

**배운 점:**
- 외부 API 타임아웃 제약 사항 사전 확인 중요
- 비동기 처리의 강력함
- 사용자 경험 (즉시 피드백) 고려

**결과:**
- 리포트 생성 시간 83% 단축 (체감)
- Slack 타임아웃 문제 완전 해결
- 사용자는 "생성 시작" 메시지 즉시 수신

---

### 🔥 Challenge 3: PostgreSQL 성능 저하

**문제 상황:**
- 대화 데이터 100개 이상 시 쿼리 느려짐 (10초+)
- 대시보드 로딩 시간 길어짐
- N+1 쿼리 문제 발견

**시도한 해결책:**
1. ❌ 데이터 샘플링 (최근 50개만) → 전체 통계 못 봄
2. ❌ 쿼리 그대로 유지 → 성능 개선 없음
3. ✅ **인덱싱 + JOIN 최적화 + 배치 처리**

**배운 점:**
- 인덱스가 성능에 얼마나 중요한지 체감
- EXPLAIN ANALYZE로 실행 계획 분석 필수
- SQLAlchemy lazy loading의 함정

**결과:**
- 쿼리 응답 시간 10초 → 1.5초 (85% 개선)
- 대시보드 로딩 빨라짐
- 사용자 경험 대폭 향상

---

### 🔥 Challenge 4: Timezone datetime 버그

**문제 상황:**
- 피드백 데이터가 0건으로 조회됨
- SQL 쿼리는 정상인데 결과 없음
- 디버깅 어려움

**시도한 해결책:**
1. ❌ 쿼리 여러 번 수정 → 여전히 0건
2. ❌ 데이터 문제로 판단 → 실제로는 데이터 존재
3. ✅ **날짜 비교 방식 변경 (string → datetime object)**

**배운 점:**
- PostgreSQL timezone-aware datetime 처리 주의
- 문자열 날짜 비교의 위험성
- 데이터 타입 일치 중요성

**결과:**
- 피드백 데이터 정상 조회
- 리포트 차트 정상 생성
- 타임존 관련 버그 완전 해결

---

## 배운 점

### 🎓 기술적 학습

**1. AI/LLM 실무 활용**
- OpenAI API 사용법 (GPT-4, Embeddings)
- 프롬프트 엔지니어링의 중요성
- RAG 패턴이 실무에서 왜 필수인지 이해
- LLM의 한계와 보완 방법

**2. Backend 아키텍처**
- 모듈화된 구조의 장점 (routers, services, utils)
- 의존성 주입 패턴 (Dependency Injection)
- 비동기 처리의 강력함 (async/await)
- 레이어 분리의 중요성

**3. Database 설계**
- 하이브리드 DB 아키텍처 (관계형 + 벡터)
- 인덱싱의 중요성
- 쿼리 최적화 기법
- 데이터 정규화 vs 비정규화 트레이드오프

**4. 자동화의 가치**
- 반복 작업은 무조건 자동화
- 스케줄러로 운영 부담 대폭 감소
- 모니터링 자동화로 문제 조기 발견

**5. 문서화의 힘**
- 좋은 문서는 협업과 유지보수를 쉽게 만듦
- README.md가 프로젝트 첫인상을 결정
- API 문서는 개발자 경험(DX)의 핵심

### 💡 소프트 스킬

**1. 자기주도 학습**
- 공식 문서 읽기의 중요성
- Stack Overflow보다 공식 문서가 정확
- 커뮤니티 활용 (GitHub Discussions, Discord)

**2. 문제 해결 능력**
- 문제를 작게 나눠서 해결
- 가설 수립 → 실험 → 검증 사이클
- 로그와 디버거가 최고의 친구

**3. 시간 관리**
- 완벽보다 완성이 중요
- 80/20 법칙 적용 (핵심 20%에 집중)
- 데드라인 설정의 중요성

**4. 꾸준함의 힘**
- 매일 2-3시간씩 6개월 = 큰 변화
- 작은 성과를 축적하는 것의 가치
- "1% 매일 성장"의 복리 효과

---

## 아쉬운 점

### 😔 기술적 아쉬움

**1. 테스트 코드 부족**
- Unit Test 거의 작성 안 함
- 통합 테스트 미흡
- TDD 적용 못 함

**개선 방안:**
- pytest 학습 및 적용
- 커버리지 80% 목표
- CI/CD에 테스트 통합

**2. 보안 고려 부족**
- 인증/인가 시스템 없음
- API Key 노출 위험
- Rate Limiting 미적용

**개선 방안:**
- JWT 인증 추가
- 환경변수 암호화
- API Rate Limiting 구현

**3. 성능 최적화 미흡**
- 캐싱 전략 부족 (Redis 미사용)
- 쿼리 최적화 여지 많음
- 프론트엔드 번들 최적화 안 함

**개선 방안:**
- Redis 캐싱 레이어 추가
- 쿼리 프로파일링 정기적 수행
- Vite 빌드 최적화

**4. 모니터링 부족**
- APM (Application Performance Monitoring) 없음
- 에러 트래킹 시스템 없음
- 로그 분석 도구 미사용

**개선 방안:**
- Sentry 에러 트래킹 도입
- ELK 스택 또는 Datadog 검토
- 알림 시스템 강화

### 📝 프로세스 아쉬움

**1. 기획 단계 부족**
- 명확한 요구사항 정의 없이 시작
- 사용자 페르소나 미설정
- MVP 범위 불명확

**2. 코드 리뷰 부재**
- 혼자 진행하다 보니 코드 리뷰 없음
- 나쁜 습관 고착화 우려
- 다른 관점 부족

**3. 문서화 후순위**
- 개발 끝나고 문서 작성
- 문서와 코드 불일치 발생
- 시간 압박으로 문서 부실

**4. 블로그 포스팅 미흡**
- 학습 과정 기록 안 함
- 트러블슈팅 과정 문서화 안 함
- 커뮤니티 기여 부족

---

## Next Steps

### 🚀 단기 목표 (1-2개월)

**기술 개선**
- [ ] JWT 인증 시스템 추가
- [ ] pytest 테스트 코드 작성 (커버리지 80%)
- [ ] Redis 캐싱 레이어 추가
- [ ] Sentry 에러 트래킹 도입
- [ ] API Rate Limiting 구현

**콘텐츠 제작**
- [ ] 기술 블로그 포스트 3개 작성
  - "RAG 시스템 구축 완벽 가이드"
  - "FastAPI + LangChain 실전 통합"
  - "6개월 만에 AI 개발자 되기"
- [ ] YouTube 데모 영상 제작
- [ ] GitHub Star 100개 목표

**포트폴리오 강화**
- [ ] 라이브 데모 사이트 배포
- [ ] 스크린샷 및 GIF 추가
- [ ] 사용자 가이드 동영상 제작
- [ ] 포트폴리오 웹사이트 구축

### 🎯 중기 목표 (3-6개월)

**프로젝트 확장**
- [ ] 다국어 지원 (i18n)
- [ ] 모바일 앱 (React Native)
- [ ] 음성 인터페이스 (STT/TTS)
- [ ] 멀티모달 지원 (이미지, 문서)

**비즈니스**
- [ ] 첫 유료 고객 확보
- [ ] 크몽/위시켓 프로젝트 수주
- [ ] SaaS 형태로 전환 검토
- [ ] 오픈소스 커뮤니티 빌딩

**커리어**
- [ ] AI 백엔드 개발자 이직
- [ ] 기술 컨퍼런스 발표
- [ ] AI 스터디 리딩
- [ ] 강의 또는 멘토링 시작

### 🌟 장기 목표 (6-12개월)

**기술 심화**
- [ ] LangGraph 고급 패턴 마스터
- [ ] 파인튜닝 (Fine-tuning) 경험
- [ ] 자체 LLM 호스팅 (Ollama, vLLM)
- [ ] 에이전트 시스템 (Multi-Agent)

**영향력 확대**
- [ ] GitHub Star 1000개
- [ ] 기술 블로그 구독자 1000명
- [ ] YouTube 구독자 500명
- [ ] 오픈소스 기여 활발히

**수익화**
- [ ] 월 100만원 이상 수익
- [ ] SaaS 런칭
- [ ] 개발자 도구 판매
- [ ] 온라인 강의 제작

---

## 마무리하며

### 💭 소감

**6개월 전의 나에게:**
> "AI는 어렵고 멀게만 느껴지지? 하지만 걱정하지 마. 하루 2-3시간씩 꾸준히 하면
> 6개월 후엔 RAG 시스템을 구축하고, 자동화 시스템을 만들고, 실시간 대시보드를
> 개발하는 너 자신을 발견하게 될 거야. 완벽하지 않아도 괜찮아. 시작하는 것이
> 가장 중요해."

**6개월 후의 나:**
> "믿을 수 없을 만큼 성장했다. FastAPI도 LangChain도 RAG도 모두 낯설었는데,
> 이제는 프로덕션 수준의 시스템을 구축할 수 있게 되었다. 물론 아직 부족한 점이
> 많지만, 그것이 다음 6개월의 목표가 될 것이다. 가장 뿌듯한 건 포기하지 않았다는 것."

### 🙏 감사의 말

**공식 문서 작성자들에게:**
- FastAPI, LangChain, Streamlit의 훌륭한 문서 덕분에 빠르게 학습할 수 있었습니다.

**오픈소스 커뮤니티에게:**
- Stack Overflow, GitHub Discussions의 수많은 답변들이 큰 도움이 되었습니다.

**미래의 나에게:**
- 이 회고를 읽으면서 초심을 잃지 말고, 계속 성장하는 개발자가 되길 바랍니다.

**이 문서를 읽는 당신에게:**
- 혹시 AI 개발에 도전하고 싶으신가요? 시작하세요. 6개월 후의 당신은 지금과는
  완전히 다른 모습일 겁니다. 응원합니다! 🚀

---

## 📚 참고 자료

**학습 자료**
- [FastAPI 공식 문서](https://fastapi.tiangolo.com/)
- [LangChain 공식 문서](https://python.langchain.com/)
- [OpenAI API 문서](https://platform.openai.com/docs/)
- [PostgreSQL 튜토리얼](https://www.postgresql.org/docs/)

**프로젝트 링크**
- [GitHub 저장소](https://github.com/space-cap/ai-career-6months)
- [API Reference](./api_reference.md)
- [System Architecture](./system_flow.mmd)
- [Portfolio Guide](./portfolio_guide.md)

**블로그 포스트 (예정)**
- RAG 시스템 구축 완벽 가이드
- FastAPI + LangChain 실전 통합
- 6개월 만에 AI 개발자 되기

---

**작성일**: 2025-01-23
**작성자**: AI Career 6 Months 프로젝트 개발자
**버전**: 1.0

> "The only way to do great work is to love what you do." - Steve Jobs

**6개월간의 여정을 마치며, 다음 6개월의 시작을 준비합니다.** 🚀
