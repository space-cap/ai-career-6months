완.전.히 좋은 질문이에요 👏
이건 **10주차의 핵심 관리 작업 중 하나**예요 —
“서비스가 돌아가고 있으니, 이제 쌓이는 데이터를 주기적으로 정리하고 백업하자”는 단계죠.

---

# 🧭 목표

* `conversation_log` 같은 테이블이 무한히 커지는 것을 방지
* 오래된 데이터는 **CSV로 백업** 후 **DB에서 삭제**
* 필요 시 자동화(scheduler or cron)로 주기적 실행

---

## 📁 **파일 이름:** `app/utils/db_cleanup.py`

```python
"""
db_cleanup.py
----------------------------------------
오래된 로그 백업 및 정리 스크립트
----------------------------------------
- conversation_log 테이블에서 일정 기간 지난 데이터 백업
- CSV로 저장 후 원본 DB에서 삭제
- Slack 전송 or 로컬 저장 옵션 지원
"""

import os
import pandas as pd
from datetime import datetime, timedelta
from sqlalchemy import create_engine, text

# -----------------------------------
# 1️⃣ DB 연결 설정
# -----------------------------------
DATABASE_URL = os.getenv("DATABASE_URL", "sqlite:///./local.db")
engine = create_engine(DATABASE_URL)

# 백업 폴더 생성
BACKUP_DIR = os.path.join(os.path.dirname(os.path.dirname(__file__)), "..", "backups")
os.makedirs(BACKUP_DIR, exist_ok=True)

# -----------------------------------
# 2️⃣ 기본 설정값
# -----------------------------------
# 예: 30일 지난 로그를 백업 및 삭제
RETENTION_DAYS = int(os.getenv("LOG_RETENTION_DAYS", 30))

def backup_and_cleanup_logs():
    """오래된 로그 백업 및 삭제"""
    cutoff_date = datetime.utcnow() - timedelta(days=RETENTION_DAYS)
    print(f"🗓️  백업 기준일: {cutoff_date}")

    # 오래된 로그 가져오기
    query = text(f"""
        SELECT * FROM conversation_log
        WHERE created_at < :cutoff
    """)
    df = pd.read_sql(query, engine, params={"cutoff": cutoff_date})

    if df.empty:
        print("✅ 백업할 오래된 로그가 없습니다.")
        return

    # -----------------------------------
    # 3️⃣ CSV 파일로 백업
    # -----------------------------------
    backup_filename = f"conversation_log_backup_{cutoff_date.strftime('%Y%m%d')}.csv"
    backup_path = os.path.join(BACKUP_DIR, backup_filename)
    df.to_csv(backup_path, index=False, encoding="utf-8-sig")

    print(f"💾 백업 완료: {backup_path} ({len(df)} rows)")

    # -----------------------------------
    # 4️⃣ DB에서 삭제
    # -----------------------------------
    delete_query = text("""
        DELETE FROM conversation_log
        WHERE created_at < :cutoff
    """)
    with engine.begin() as conn:
        conn.execute(delete_query, {"cutoff": cutoff_date})

    print(f"🧹 {len(df)}개의 오래된 로그 삭제 완료 ✅")


if __name__ == "__main__":
    backup_and_cleanup_logs()
```

---

## ⚙️ **작동 순서**

1. `conversation_log` 테이블에서 `created_at` 기준으로 30일 이상 된 데이터 조회
2. 그 데이터를 `backups/conversation_log_backup_YYYYMMDD.csv` 로 저장
3. CSV 백업이 끝나면 DB에서 해당 레코드 삭제

---

## 📊 **실행 예시**

```bash
poetry run python -m app.utils.db_cleanup
```

출력 예시 👇

```
🗓️  백업 기준일: 2025-09-15 00:00:00
💾 백업 완료: backups/conversation_log_backup_20250915.csv (124 rows)
🧹 124개의 오래된 로그 삭제 완료 ✅
```

---

## 🧩 **Render 무료 플랜에서도 자동화 가능**

Render 무료 플랜에서는 cron이 없으므로
→ `/run-cleanup` 엔드포인트로 만들고
→ 외부 스케줄러(cron-job.org)가 주기적으로 호출하도록 구성 가능해요.

예:
📁 `app/routes/maintenance.py`

```python
from fastapi import APIRouter, BackgroundTasks
from app.utils.db_cleanup import backup_and_cleanup_logs

router = APIRouter()

@router.get("/run-cleanup")
def run_cleanup(background_tasks: BackgroundTasks):
    background_tasks.add_task(backup_and_cleanup_logs)
    return {"status": "Cleanup started in background."}
```

---

## 💾 **폴더 구조 예시**

```
ai-career-6months/
 ┣ app/
 ┃ ┣ utils/
 ┃ ┃ ┣ report_utils.py
 ┃ ┃ ┗ db_cleanup.py      👈 (지금 만든 파일)
 ┃ ┗ routes/
 ┃   ┗ maintenance.py     👈 /run-cleanup 라우트
 ┣ backups/               👈 백업 CSV 저장 폴더
 ┣ reports/
 ┗ ...
```

---

## 🧠 **추가 확장 아이디어**

| 기능          | 설명                                     |
| ----------- | -------------------------------------- |
| ☁️ Slack 알림 | 백업 완료 후 Slack에 “로그 정리 완료” 메시지 전송       |
| 📬 Email 알림 | 관리자 이메일로 백업 결과 자동 전송                   |
| 💾 Cloud 저장 | AWS S3 / Google Drive API 연동으로 클라우드 백업 |
| 🔁 자동 스케줄링  | `schedule` 모듈로 매주 월요일 09:00 자동 실행      |
| 🔒 보안       | CSV 파일에 암호화(zip + password) 적용         |

---

## ✅ **정리**

| 항목            | 설명                                          |
| ------------- | ------------------------------------------- |
| 파일명           | `app/utils/db_cleanup.py`                   |
| 기본 동작         | 오래된 로그(기본 30일 초과) 백업 + 삭제                   |
| 출력 폴더         | `backups/`                                  |
| 실행 명령         | `poetry run python -m app.utils.db_cleanup` |
| Render 무료 자동화 | `/run-cleanup` 엔드포인트 + 외부 스케줄러              |

---

원하신다면 ✨
이걸 **“Slack 자동 알림 버전 (백업 완료 → Slack 메시지 발송)”** 으로 확장해서 만들어드릴까요?
→ 매주 월요일 아침에 “💾 7일치 로그 백업 완료” 메시지가 자동으로 Slack에 옵니다.
